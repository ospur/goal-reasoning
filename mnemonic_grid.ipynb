{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnemonic_grid.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wnU9J8zWHPo4-tMzIhDrBFAqOJADwaEx","authorship_tag":"ABX9TyM3slGSnKAREiWnJxjJqcm8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"v3Svgf7wM4xF"},"source":["import tensorflow as tf\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyUK843BbDNd"},"source":["class Grid:\n","\n","    def reset(self):\n","        self.items = {(1, 4), (5, 0), (5, 4)}\n","        self.view = np.zeros((6, 5))\n","        self.current_state = [1, 0]\n","        self.inventory = []\n","        self.delivered = set()\n","        self.steps = 0\n","        return self.vectorize(self.current_state)\n","\n","    def step(self, action):\n","        # Right\n","        if action == 0:\n","            self.current_state[1] = min(self.current_state[1] + 1, 4)\n","        # Up\n","        if action == 1:\n","            if self.current_state == [1, 2]:\n","                self.current_state[0] -= 1\n","            else:\n","                self.current_state[0] = max(self.current_state[0] - 1, 1)    \n","        # Left\n","        if action == 2:\n","            self.current_state[1] = max(self.current_state[1] - 1, 0)\n","        # Down\n","        if action == 3:\n","            self.current_state[0] = min(self.current_state[0] + 1, 5)\n","        self.steps += 1\n","\n","        # Pick up\n","        s = tuple(self.current_state)\n","        if s in self.items and not self.inventory:\n","            self.inventory.append(s)\n","            self.items.remove(s)\n","\n","        # Drop off\n","        if self.current_state == [1, 0] and self.inventory:\n","            self.delivered.add(self.inventory.pop())\n","    \n","        if self.current_state == [0, 2]:\n","            if self.delivered == {(1, 4), (5, 0), (5, 4)}:\n","                return self.vectorize(self.current_state), 1.0, True\n","            return self.vectorize(self.current_state), 0.0, True\n","\n","        if self.steps == 60:\n","            return self.vectorize(self.current_state), 0.0, True\n","\n","        return self.vectorize(self.current_state), 0.0, False\n","\n","    def vectorize(self, state):\n","        self.view[0] = [-1, -1, 0, -1, -1]\n","        self.view[1:] = 0\n","        self.view[self.current_state[0]][self.current_state[1]] = 1\n","        return self.view"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0WlPWtD1bDUz"},"source":["class Recurrent_hREINFORCE:\n","\n","    def __init__(self):\n","        self.memory = []\n","        self.states = []\n","        self.options = []\n","        self.rewards = []\n","        self.discount_rate = 0.99\n","        self.learning_rate = 0.001\n","        self.model = self.build_model()\n","\n","    def build_model(self):\n","        model = tf.keras.Sequential()\n","        model.add(tf.keras.layers.GRU(64, input_shape=(None, 30), return_sequences=True))\n","        model.add(tf.keras.layers.Dense(5, activation='softmax'))\n","        model.compile(loss=\"categorical_crossentropy\",\n","                    optimizer=tf.keras.optimizers.Adam(lr=self.learning_rate, clipnorm=1.0))\n","        model.summary()\n","        return model\n","\n","    def select_option(self, state_list):\n","        current = loc_to_option(view_to_loc(state_list[-1]))\n","        applicable = np.delete(np.arange(5), current)\n","        state_list = np.reshape(state_list, (1, len(state_list), 30))\n","        prob = np.delete(self.model.predict(state_list)[0, -1], current) \n","        if np.sum(prob) == 0:\n","            return np.random.choice(applicable)\n","        prob /= np.sum(prob)\n","        return np.random.choice(applicable, 1, p=prob)[0]\n","\n","    def store_transition(self, state, option, reward):\n","        self.states.append(state)\n","        self.options.append(option)\n","        self.rewards.append(reward)\n","\n","    def store_episode(self):\n","        self.memory.append((self.states, self.options, self.rewards))\n","        self.states = []\n","        self.options = []\n","        self.rewards = []\n","\n","    def update(self, episode):\n","        trajectory = self.memory[episode]\n","        states = trajectory[0]\n","        options = trajectory[1]\n","        rewards = trajectory[2]\n","\n","        T = len(states)\n","\n","        returns = np.zeros(T)\n","        returns[-1] = rewards[-1]\n","        for t in reversed(range(1, T)):\n","            returns[t - 1] = rewards[t - 1] + self.discount_rate * returns[t]\n","\n","        x = np.reshape(states, (1, T, 30))\n","        y = np.zeros((1, T, 5))\n","\n","        for i in range(T):\n","            y[0, i, options[i]] = returns[i]\n","\n","        self.model.fit(x, y, epochs=1, verbose=0)\n","    \n","    def batch_update(self, start, end):\n","        for episode in range(start, end):\n","            self.update(episode)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCG7tBaCbDdg"},"source":["def view_to_loc(view):\n","    index = np.where(view == 1) \n","    return [index[0][0], index[1][0]]\n","\n","def option_to_loc(option):\n","    if option == 0:\n","        return [1, 0]\n","    if option == 1:\n","        return [1, 4]\n","    if option == 2:\n","        return [5, 0]\n","    if option == 3:\n","        return [5, 4]\n","    if option == 4:\n","        return [0, 2]\n","\n","def loc_to_option(loc):\n","    if loc == [1, 0]:\n","        return 0\n","    if loc == [1, 4]:\n","        return 1\n","    if loc == [5, 0]:\n","        return 2\n","    if loc == [5, 4]:\n","        return 3\n","    if loc == [0, 2]:\n","        return 4\n","\n","def select_action(view, option):\n","    view_loc = view_to_loc(view)\n","    option_loc = option_to_loc(option)\n","    if view_loc[0] < option_loc[0]:\n","        return 3\n","    if view_loc[1] < option_loc[1]:\n","        return 0\n","    if view_loc[0] > option_loc[0]:\n","        return 1\n","    if view_loc[1] > option_loc[1]:\n","        return 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7OGWotvbDlW"},"source":["def train(start, runs):\n","    if start == 0:\n","        rewards = np.zeros((runs, 20000))\n","    else:\n","        rewards = np.load(f\"./drive/My Drive/grid/mnemonic_rewards.npy\")\n","   \n","    for run in range(start, runs):\n","        print(\"\\nRun \" + str(run))\n","\n","        env = Grid()\n","        meta = Recurrent_hREINFORCE()\n","\n","        for episode in range(20000):\n","            # print(\"\\nEpisode \" + str(episode))\n","\n","            done = False\n","            meta_state = env.reset()\n","            episode_reward = 0\n","\n","            state_list = []\n","            state_list.append(meta_state)\n","\n","            while not done:\n","                option = meta.select_option(state_list)\n","                reached = view_to_loc(meta_state) == option_to_loc(option)\n","                \n","                option_reward = 0\n","\n","                state = meta_state\n","                while not done and not reached:\n","                    action = select_action(state, option)\n","                    next_state, reward, done = env.step(action)\n","                    \n","                    option_reward += reward\n","                    episode_reward += reward\n","                    \n","                    reached = view_to_loc(next_state) == option_to_loc(option)\n","                    state = next_state\n","\n","                meta.store_transition(meta_state, option, option_reward)\n","                meta_state = state\n","                state_list.append(meta_state)\n","\n","            meta.store_episode()\n","            meta.update(episode)\n","\n","            rewards[run, episode] = episode_reward\n","\n","            # print(\"reward =  \" + str(episode_reward))\n","\n","            if episode % 1000 == 999:\n","                np.save(f\"./drive/My Drive/grid/mnemonic_rewards\", rewards)\n","        \n","        meta.model.save(f\"./drive/My Drive/grid/mnemonic_{run}_{episode}.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Vce4Umqo_Y5","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1582521211721,"user_tz":300,"elapsed":4290096,"user":{"displayName":"Weihang Yuan","photoUrl":"","userId":"13848464180676312974"}},"outputId":"653eeb4a-5aaf-431b-9ac3-698e28497dfe"},"source":["train(0, 10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Run 0\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru (GRU)                    (None, None, 64)          18240     \n","_________________________________________________________________\n","dense (Dense)                (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","\n","Run 1\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_1 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 2\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_2 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 3\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_3 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 4\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_4 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 5\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_5 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 6\n","Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_6 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 7\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_7 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 8\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_8 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_8 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n","\n","Run 9\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","gru_9 (GRU)                  (None, None, 64)          18240     \n","_________________________________________________________________\n","dense_9 (Dense)              (None, None, 5)           325       \n","=================================================================\n","Total params: 18,565\n","Trainable params: 18,565\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]}]}